{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10: Cleaning data with Regular Expressions\n",
    "\n",
    "Time to use regular expressions!\n",
    "\n",
    "# Hints and notes\n",
    "\n",
    "### Opening files in subdirectories\n",
    "\n",
    "Notice that this notebook might be **homework/**, but!!! the csvs and text files might be in **homework/scraped/** or **/homework/scraped/minutes_pdfs** or **/homework/pdfs/**. To open a file in a subdirectory, instead of having the filename be `\"file.csv\"` you'll just use `\"some/subfolder/file.csv\"`\n",
    "\n",
    "### Opening text files\n",
    "\n",
    "This will open up a file, read it in and show you the first 500 characters.\n",
    "\n",
    "```python\n",
    "contents = open(\"your-filename.txt\").read()\n",
    "contents[0:500]\n",
    "```\n",
    "\n",
    "> You might need `open(\"your-filename.txt\", encoding=\"utf8\").read()`\n",
    "\n",
    "### Using regex\n",
    "\n",
    "For some dumb reason you need to put `r` in front of the string you use when you're talking about regex. Just plain `\"(\\d\\d\\d)\"` will usually work, but *sometimes* it won't and you'll need `r\"(\\d\\d\\d)`. It's best to just use the `r` all of the time, if you can remember!\n",
    "\n",
    "### Using `.str.extract`\n",
    "\n",
    "When you use `.str.extract`, you're always going to **capture one thing** and save it to a new column. You need to wrap the things you're interested in with parenthesis `(` `)`.\n",
    "\n",
    "```python\n",
    "df['phone_number'] = df['old_column'].str.extract(r\"My phone number is (\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d)\")\n",
    "```\n",
    "\n",
    "### Setting pandas options\n",
    "\n",
    "Pandas has a lot of options, like how many columns or rows it will show you, or how many characters it will show in a column before it stops showing you anything. Here are a few useful ones:\n",
    "\n",
    "* `display.max_cols`: Number of columns to show at once\n",
    "* `display.max_rows`: Number of rows to show at once\n",
    "* `display.max_colwidth`: Maximum number of characters displayed from a string\n",
    "\n",
    "You can set them using `pd.set_option(\"display.max_rows\", 1000)`, for example, to show 1000 rows at a time. You can find a lot more at https://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html\n",
    "\n",
    "### Regular expressions reference\n",
    "\n",
    "I personally think http://www.regular-expressions.info/ is a wonderful wonderful reference (and tutorial), even if it's ugly! But here's a quick reference for you:\n",
    "\n",
    "* `\\d` is a digit\n",
    "* `\\d*` is zero or more digits \n",
    "* `\\d+` is one or more digits\n",
    "* `.` matches anything for ONE character\n",
    "* `.*` is \"give me anything forever\"\n",
    "* `\\s` is whitespace, a.k.a. spaces and tabs\n",
    "* `\\w` is a word character, which includes capital and lowercase letters, numbers and hyphens.\n",
    "* You can put `*` after anything, so `\\w*` would mean \"as many word characters as you can find\"\n",
    "* `\\b` is a word boundary (you'll need the `r\"\"` thing for this one)\n",
    "* `( )` is a \"capture group\" for saving something\n",
    "* `\\1` is used when doing find/replace to say \"put the first captured group here\" (note, it's a dollar sign instead of a backslash in some editors)\n",
    "* `[ABCDE]` is a character class, which means \"match one of these, I don't care which\"\n",
    "* dollar sign means \"end of the line\"\n",
    "* caret ^ means \"beginning of the line\"\n",
    "* `\\.` means \"no really seriously I mean a period not just anything\"\n",
    "* You can use `\\` with anything else that would normally be a special character, too, not just periods. `(` or `[` or whatever.\n",
    "\n",
    "### Cleaning up extracted columns\n",
    "\n",
    "Sometimes you get `\\n` (newlines) or spaces or `\\t` (tabs) or stuff at the beginning or the end of your column. `.str.strip()` will usually take care of that, just attach it after your `.str.extract()`\n",
    "\n",
    "After you extract something, it's still a string even though you look at it and know it's a number. Use `.astype(int)` to turn it into an integer (no decimal) or `.astype(float)` to turn it into a float (yes decimal)\n",
    "\n",
    "### Writing regular expressions in general\n",
    "\n",
    "Even if I'm using regex in pandas or Python, I like to test them in my text editor with \"Find.\" The highlighting really helps me see if I'm matching things! I also like to think \"what stays the same?\" when designing patterns, write those parts first, then fill in the blanks with what I want to capture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "There might be more, I just wanted to put this up here for the `pd.set_option` part. It allows you to see a lot of content in a single column of pandas, which will be important for some parts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using `.str.extract` to pull data from columns in pandas\n",
    "\n",
    "## 1.1 H&M\n",
    "\n",
    "Open up `hm.csv` from the `scraped` directory. I want **four new columns**:\n",
    "\n",
    "1. `price_original`, the original price, one of the new price\n",
    "2. `price_discounted`, the discounted price\n",
    "3. `pct_discount`, the percent discount\n",
    "4. `article_id`, the article id (from the url)\n",
    "\n",
    "Save as **hm_cleaned.csv**.\n",
    "\n",
    "**Note:** When you look at it, it... won't look right. I don't know why, pandas is weird. Look at the `price` column by itself using `df['price']` before you write your regex.\n",
    "\n",
    "**Tip:** Remember that `$` is a special regex symbol! You might need to escape it.\n",
    "\n",
    "**Tip:** When doing `.str.extract`, the whole match doesn't get captured, only what you put `()` around! Think about anchoring to different points of the string, or things in the string.\n",
    "\n",
    "**Tip:** Not all prices have cents!\n",
    "\n",
    "**Tip:** Your first instinct about how to compute the percent discount is probably wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = pd.read_csv(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/scraped/hm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washed Linen Duvet Cover Set</td>\n",
       "      <td>$59.99 $129</td>\n",
       "      <td>http://www.hm.com/us/product/13472?article=13472-N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candle in Glass Jar</td>\n",
       "      <td>$6.99 $17.99</td>\n",
       "      <td>http://www.hm.com/us/product/35079?article=35079-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glittery Cushion Cover</td>\n",
       "      <td>$7.99 $17.99</td>\n",
       "      <td>http://www.hm.com/us/product/72462?article=72462-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Textured-weave Cushion Cover</td>\n",
       "      <td>$6.99 $12.99</td>\n",
       "      <td>http://www.hm.com/us/product/58926?article=58926-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stoneware Bowl</td>\n",
       "      <td>$17.99 $24.99</td>\n",
       "      <td>http://www.hm.com/us/product/74242?article=74242-A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name          price  \\\n",
       "0  Washed Linen Duvet Cover Set    $59.99 $129   \n",
       "1           Candle in Glass Jar   $6.99 $17.99   \n",
       "2        Glittery Cushion Cover   $7.99 $17.99   \n",
       "3  Textured-weave Cushion Cover   $6.99 $12.99   \n",
       "4                Stoneware Bowl  $17.99 $24.99   \n",
       "\n",
       "                                                  url  \n",
       "0  http://www.hm.com/us/product/13472?article=13472-N  \n",
       "1  http://www.hm.com/us/product/35079?article=35079-D  \n",
       "2  http://www.hm.com/us/product/72462?article=72462-A  \n",
       "3  http://www.hm.com/us/product/58926?article=58926-C  \n",
       "4  http://www.hm.com/us/product/74242?article=74242-A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_original, the original price, one of the new price\n",
    "\n",
    "hm[\"price_original\"] = hm[\"price\"].str.extract(r\" \\$(\\d*\\.?\\d*)\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_discounted, the discounted price\n",
    "\n",
    "hm[\"price_discounted\"] = hm[\"price\"].str.extract(r\"\\$(\\d*?.?\\d+) \").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pct_discount, the percent discount\n",
    "\n",
    "hm[\"pct_discount\"] = round((hm[\"price_original\"] - hm[\"price_discounted\"]) / hm[\"price_original\"] * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_id, the article id (from the url)\n",
    "\n",
    "hm[\"article_id\"] = hm[\"url\"].str.extract(r\"article=(.*)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm.head()\n",
    "hm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.to_csv(\"hm_clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hm_clean = pd.read_csv(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/hm_clean.csv\")\n",
    "\n",
    "# hm_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sci-Fi Authors\n",
    "\n",
    "Open up `sci-fi.csv` to clean. Get rid of the `\\n` on the title and and give me six new columns:\n",
    "\n",
    "* `avg_rating`\n",
    "* `rating_count`\n",
    "* `total_score`\n",
    "* `score_votes`\n",
    "* `series` the series the book belongs to\n",
    "* `series_no` the book in the series that it is\n",
    "\n",
    "For series, I'm talking about e.g. `(The Hunger Games, #1)` is `series` \"The Hunter Games\" and `series_no` 1.\n",
    "\n",
    "Save as **sci-fi_cleaned.csv**.\n",
    "\n",
    "**Tip:** You don't need regex to clean the title - there's a special thing that removes whitespace from the beginning/end of strings\n",
    "\n",
    "**Tip:** Remember that `(` and `)` are special characters\n",
    "\n",
    "**BONUS:** When you make the `total_score` column, pay close attention to it. If you notice the problem, fix it.\n",
    "\n",
    "**BONUS:** You don't need these columns to be numbers, but life would be better if they were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi = pd.read_csv(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/scraped/sci-fi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_rating</th>\n",
       "      <th>full_score</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.07 avg rating — 785,502 ratings</td>\n",
       "      <td>\\nscore: 28,539,\\n              and\\n292 people voted\\n               \\n              \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nThe Handmaid's Tale\\n</td>\n",
       "      <td>/book/show/38447.The_Handmaid_s_Tale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.34 avg rating — 5,212,935 ratings</td>\n",
       "      <td>\\nscore: 27,566,\\n              and\\n282 people voted\\n               \\n              \\n</td>\n",
       "      <td>2</td>\n",
       "      <td>\\nThe Hunger Games (The Hunger Games, #1)\\n</td>\n",
       "      <td>/book/show/2767052-the-hunger-games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.76 avg rating — 922,308 ratings</td>\n",
       "      <td>\\nscore: 20,049,\\n              and\\n205 people voted\\n               \\n              \\n</td>\n",
       "      <td>3</td>\n",
       "      <td>\\nFrankenstein, or The Modern Prometheus\\n</td>\n",
       "      <td>/book/show/18490.Frankenstein_or_The_Modern_Prometheus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.04 avg rating — 702,272 ratings</td>\n",
       "      <td>\\nscore: 17,684,\\n              and\\n185 people voted\\n               \\n              \\n</td>\n",
       "      <td>4</td>\n",
       "      <td>\\nA Wrinkle in Time (A Wrinkle in Time Quintet, #1)\\n</td>\n",
       "      <td>/book/show/18131.A_Wrinkle_in_Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.06 avg rating — 77,664 ratings</td>\n",
       "      <td>\\nscore: 16,070,\\n              and\\n165 people voted\\n               \\n              \\n</td>\n",
       "      <td>5</td>\n",
       "      <td>\\nThe Left Hand of Darkness\\n</td>\n",
       "      <td>/book/show/18423.The_Left_Hand_of_Darkness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            full_rating  \\\n",
       "0     4.07 avg rating — 785,502 ratings   \n",
       "1   4.34 avg rating — 5,212,935 ratings   \n",
       "2     3.76 avg rating — 922,308 ratings   \n",
       "3     4.04 avg rating — 702,272 ratings   \n",
       "4      4.06 avg rating — 77,664 ratings   \n",
       "\n",
       "                                                                                             full_score  \\\n",
       "0  \\nscore: 28,539,\\n              and\\n292 people voted\\n               \\n              \\n               \n",
       "1  \\nscore: 27,566,\\n              and\\n282 people voted\\n               \\n              \\n               \n",
       "2  \\nscore: 20,049,\\n              and\\n205 people voted\\n               \\n              \\n               \n",
       "3  \\nscore: 17,684,\\n              and\\n185 people voted\\n               \\n              \\n               \n",
       "4  \\nscore: 16,070,\\n              and\\n165 people voted\\n               \\n              \\n               \n",
       "\n",
       "   rank                                                  title  \\\n",
       "0     1                                \\nThe Handmaid's Tale\\n   \n",
       "1     2            \\nThe Hunger Games (The Hunger Games, #1)\\n   \n",
       "2     3             \\nFrankenstein, or The Modern Prometheus\\n   \n",
       "3     4  \\nA Wrinkle in Time (A Wrinkle in Time Quintet, #1)\\n   \n",
       "4     5                          \\nThe Left Hand of Darkness\\n   \n",
       "\n",
       "                                                      url  \n",
       "0                    /book/show/38447.The_Handmaid_s_Tale  \n",
       "1                     /book/show/2767052-the-hunger-games  \n",
       "2  /book/show/18490.Frankenstein_or_The_Modern_Prometheus  \n",
       "3                      /book/show/18131.A_Wrinkle_in_Time  \n",
       "4              /book/show/18423.The_Left_Hand_of_Darkness  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_fi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_rating    object\n",
       "full_score     object\n",
       "rank            int64\n",
       "title          object\n",
       "url            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_fi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up title\n",
    "\n",
    "sci_fi[\"title\"] = sci_fi[\"title\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_rating\n",
    "\n",
    "sci_fi[\"avg_rating\"] = sci_fi[\"full_rating\"].str.extract(r\"(\\d.*) avg\").astype(float)\n",
    "#sci_fi[\"avg_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_count\n",
    "\n",
    "#select\n",
    "sci_fi[\"rating_count\"] = sci_fi[\"full_rating\"].str.extract(r\"— (.*) ratings\")\n",
    "\n",
    "#get rid of \",\" and turn it into int\n",
    "sci_fi[\"rating_count\"] = sci_fi[\"rating_count\"].str.replace(\",\", \"\").astype(\"int\")\n",
    "#sci_fi[\"rating_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_score\n",
    "sci_fi[\"total_score\"] = sci_fi[\"full_score\"].str.extract(r\"score: (.*),\")\n",
    "\n",
    "sci_fi[\"total_score\"] = sci_fi[\"total_score\"].str.replace(\",\", \"\").astype(\"int\")\n",
    "#sci_fi[\"total_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_votes\n",
    "sci_fi[\"score_votes\"] = sci_fi[\"full_score\"].str.extract(r\"and\\n(\\d*) people voted\").astype(\"int\")\n",
    "#sci_fi[\"score_votes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series the series the book belongs to\n",
    "\n",
    "sci_fi[\"series\"] = sci_fi[\"title\"].str.extract(r\"\\((.*),?#\")\n",
    "sci_fi[\"series\"] = sci_fi[\"series\"].str.replace(\",\", \"\")\n",
    "#sci_fi[\"series\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series_no the book in the series that it is\n",
    "sci_fi[\"series_no\"] = sci_fi[\"title\"].str.extract(r\"\\(.*#(.*)\\)\")\n",
    "#sci_fi[\"series_no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_fi.to_csv(\"sci_fi_clean.csv\", index = False)\n",
    "\n",
    "# sci_fi_clean = pd.read_csv(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/sci_fi_clean.csv\")\n",
    "# sci_fi_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Where you're just doing one of my former students' projects\n",
    "\n",
    "Once upon a time my student Stefan did a project that involved some lawyer stuff. Most of the content was in PDFs, though! I converted them to text files and put them into the `pdfs` folder, and gave you code below to open up each of them and save their contents into a dataframe.\n",
    "\n",
    "What a nice dataframe! I want you to add the following columns to it:\n",
    "\n",
    "* `lawyer_app`, the applicant's lawyer (pro se means that they did it themselves, that's fine)\n",
    "* `lawyer_gov`, the government's lawyer\n",
    "* `judge`, the name of the judge\n",
    "* `access`, whether the clearance is granted or denied (although you might miss a few)\n",
    "\n",
    "Save as **court_cleaned.csv**.\n",
    "\n",
    "**Note:** You can look at the original PDFs, they're also included.\n",
    "\n",
    "**Note:** This uses a fun utility called `glob`, which is mostly fun because you use it as `glob.glob`. It's used to find files that match a certain filename pattern.\n",
    "\n",
    "**BONUS:** You'll be happy once you get the judge, but make sure it doesn't have any extra punctuation on it.\n",
    "\n",
    "**BONUS:** You can for some words using `.str.contains(\"blah\")` and save it into new columns. Maybe `has_debt`, `has_bankruptcy`, etc.\n",
    "\n",
    "> It's okay if it isn't perfect. Converting PDF into data rarely is! Usually you get 90% of it done with computers, then send people to enter the other 10% by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames = glob.glob(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs/*.txt\")\n",
    "contents = [open(filename, encoding=\"utf8\").read() for filename in filenames]\n",
    "df = pd.DataFrame({'filename': filenames, 'content': contents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-02438.h1.pdf.txt</td>\n",
       "      <td>\\n\\n                           DEPARTMENT OF DEFENSE \\n         DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n           \\n             \\n\\n \\n \\nIn the matter of: \\n \\n \\n \\n \\nApplicant for Security Clearance \\n\\n \\n \\n\\n \\n\\nISCR Case No. 11-02438 \\n\\nFor Government: Stephanie C. Hess, Esq., Department Counsel \\n\\nFor Applicant: Pro se \\n\\nAppearances \\n\\n______________ \\n\\n \\nDecision \\n\\n______________ \\n\\n \\n\\n \\n\\n \\n\\n \\n \\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-03073.h1.pdf.txt</td>\n",
       "      <td>\\n\\n                        DEPARTMENT OF DEFENSE \\n\\n         DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n \\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance \\n\\n \\n\\n \\n\\nISCR Case No. 11-03073 \\n\\n           \\n             \\n\\n) \\n) \\n) \\n) \\n) \\n \\n \\n\\n \\n \\n\\nAppearances \\n\\n______________ \\n\\n \\nDecision \\n\\n______________ \\n\\n \\n\\n \\n\\n \\n\\n \\n \\n\\nFor Government: Robert J. Kilmartin, Esq., Department Counse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-04909.h1.pdf.txt</td>\n",
       "      <td>\\n\\n            DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n    DEPARTMENT OF DEFENSE \\n\\n          \\n             \\n\\n \\n\\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance \\n\\n \\n \\n\\n \\n\\nISCR Case No. 11-04909 \\n\\n \\n\\nFor Government: Richard Stevens, Esq., Department Counsel \\n\\nFor Applicant: Pro se \\n\\n \\n\\n \\nDUFFY, James F., Administrative Judge: \\n\\n \\nApplicant  mitigated \\n\\nconsiderations). Clearance is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-07728.h1.pdf.txt</td>\n",
       "      <td>DEPARTMENT OF DEFENSE \\n\\n       DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance  \\n\\n------------------------    \\n \\n\\n \\n\\nISCR Case No. 11-07728 \\n\\n           \\n             \\n\\n) \\n) \\n) \\n) \\n) \\n \\n \\n\\n \\n\\n \\n \\n\\nAppearances \\n\\n___________ \\n\\n \\nDecision \\n\\n___________ \\n\\nFor Government: Julie R. Mendez, Esq., Department Counsel \\n\\nFor Applicant: Mark S. Zaid, Esq. \\n\\n \\n\\nHARVEY, Mark, Administrative Judge: \\n \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-08313.h1.pdf.txt</td>\n",
       "      <td>\\n\\n                           DEPARTMENT OF DEFENSE \\n         DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n \\n\\nISCR Case No. 11-08313 \\n\\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance \\n\\n--------------- \\n \\n\\n \\n\\n           \\n             \\n\\n) \\n) \\n) \\n) \\n) \\n \\n\\n \\n \\n\\nAppearances \\n\\n______________ \\n\\n \\nDecision \\n\\n______________ \\n\\nFor Government: Julie R. Mendez, Esquire, Department Counsel \\n\\nFo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   filename  \\\n",
       "0  C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-02438.h1.pdf.txt   \n",
       "1  C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-03073.h1.pdf.txt   \n",
       "2  C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-04909.h1.pdf.txt   \n",
       "3  C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-07728.h1.pdf.txt   \n",
       "4  C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework-pdfs/pdfs\\11-08313.h1.pdf.txt   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               content  \n",
       "0                                                                \\n\\n                           DEPARTMENT OF DEFENSE \\n         DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n           \\n             \\n\\n \\n \\nIn the matter of: \\n \\n \\n \\n \\nApplicant for Security Clearance \\n\\n \\n \\n\\n \\n\\nISCR Case No. 11-02438 \\n\\nFor Government: Stephanie C. Hess, Esq., Department Counsel \\n\\nFor Applicant: Pro se \\n\\nAppearances \\n\\n______________ \\n\\n \\nDecision \\n\\n______________ \\n\\n \\n\\n \\n\\n \\n\\n \\n \\n\\...  \n",
       "1                                                                \\n\\n                        DEPARTMENT OF DEFENSE \\n\\n         DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n \\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance \\n\\n \\n\\n \\n\\nISCR Case No. 11-03073 \\n\\n           \\n             \\n\\n) \\n) \\n) \\n) \\n) \\n \\n \\n\\n \\n \\n\\nAppearances \\n\\n______________ \\n\\n \\nDecision \\n\\n______________ \\n\\n \\n\\n \\n\\n \\n\\n \\n \\n\\nFor Government: Robert J. Kilmartin, Esq., Department Counse...  \n",
       "2                                                                \\n\\n            DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n    DEPARTMENT OF DEFENSE \\n\\n          \\n             \\n\\n \\n\\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance \\n\\n \\n \\n\\n \\n\\nISCR Case No. 11-04909 \\n\\n \\n\\nFor Government: Richard Stevens, Esq., Department Counsel \\n\\nFor Applicant: Pro se \\n\\n \\n\\n \\nDUFFY, James F., Administrative Judge: \\n\\n \\nApplicant  mitigated \\n\\nconsiderations). Clearance is ...  \n",
       "3     DEPARTMENT OF DEFENSE \\n\\n       DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance  \\n\\n------------------------    \\n \\n\\n \\n\\nISCR Case No. 11-07728 \\n\\n           \\n             \\n\\n) \\n) \\n) \\n) \\n) \\n \\n \\n\\n \\n\\n \\n \\n\\nAppearances \\n\\n___________ \\n\\n \\nDecision \\n\\n___________ \\n\\nFor Government: Julie R. Mendez, Esq., Department Counsel \\n\\nFor Applicant: Mark S. Zaid, Esq. \\n\\n \\n\\nHARVEY, Mark, Administrative Judge: \\n \\...  \n",
       "4                                                              \\n\\n                           DEPARTMENT OF DEFENSE \\n         DEFENSE OFFICE OF HEARINGS AND APPEALS \\n\\n \\n\\nISCR Case No. 11-08313 \\n\\n \\nIn the matter of: \\n \\n \\n \\nApplicant for Security Clearance \\n\\n--------------- \\n \\n\\n \\n\\n           \\n             \\n\\n) \\n) \\n) \\n) \\n) \\n \\n\\n \\n \\n\\nAppearances \\n\\n______________ \\n\\n \\nDecision \\n\\n______________ \\n\\nFor Government: Julie R. Mendez, Esquire, Department Counsel \\n\\nFo...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Okay, now do the work and **make those new columns!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lawyer_app\"] = df[\"content\"].str.extract(r\"For Applicant\\s{0,}(.*)\", re.IGNORECASE)\n",
    "\n",
    "df[\"lawyer_app\"] = df[\"lawyer_app\"].str.replace(\":\",\"\")\n",
    "df[\"lawyer_app\"] = df[\"lawyer_app\"].str.strip()\n",
    "\n",
    "#df[\"lawyer_app\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lawyer_gov\"] = df[\"content\"].str.extract(r\"For Government\\s{0,}(.*)\", re.IGNORECASE)\n",
    "\n",
    "df[\"lawyer_gov\"] = df[\"lawyer_gov\"].str.replace(\":\",\"\")\n",
    "df[\"lawyer_gov\"] = df[\"lawyer_gov\"].str.strip()\n",
    "\n",
    "#df[\"lawyer_gov\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# judge, the name of the judge\n",
    "\n",
    "df[\"judge\"] = df[\"content\"].str.extract(r\"(\\w.*)\\n{1,}Administrative Judge\")\n",
    "\n",
    "#df[\"judge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access, whether the clearance is granted or denied (although you might miss a few)\n",
    "df[\"access\"] = df[\"content\"].str.extract(r\"is ([gad].*ed)\\.\",re.IGNORECASE)\n",
    "df[\"access\"] = df[\"access\"].str.replace(\"AFFIRMED\", \"affirmed\")\n",
    "#is there a difference between afrirmed and granted ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_foreign\"] = df[\"content\"].str.contains(\"foreign\", re.IGNORECASE)\n",
    "df[\"has_China\"] = df[\"content\"].str.contains(\"China\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"court_cleaned.csv\", index = False)\n",
    "\n",
    "# court_cleaned = pd.read_csv(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/court_cleaned.csv\")\n",
    "# court_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading books\n",
    "\n",
    "When you're doing text work, you're legally obligated work on Jane Austen's Pride and Prejudice (at least I *think* so). Let's do some naive analysis of it!\n",
    "\n",
    "## Read in Jane Austen's Pride and Prejudice (without moving the file!)\n",
    "\n",
    "It's in the `data/` directory, and named `Austen_Pride.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = open(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/data/Austen_Pride.txt\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the first 500 or so characters of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Pride and Prejudice\\nby Jane Austen\\nChapter 1\\nIt is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\\nHowever little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered the rightful property of some one or other of their daughters.\\n\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that Nethe'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a regular expression to find every \"he\" or \"she\" in the book. There should be about 3000 of them.\n",
    "\n",
    "**Tip:** Do you know about **word boundaries?** `\\b` means \"the beginning of end of a word.\"\n",
    "\n",
    "**Tip:** You might also want to use `re.IGNORECASE`. Maybe you'll need to google it? \n",
    "\n",
    "**Tip:** Do NOT use `re.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'She',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'She',\n",
       " 'She',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'She',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'She',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'He',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'She',\n",
       " 'She',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'She',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'She',\n",
       " 'He',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'He',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'He',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'he',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " 'he',\n",
       " 'she',\n",
       " 'he',\n",
       " 'She',\n",
       " 'he',\n",
       " 'she',\n",
       " 'She',\n",
       " 'she',\n",
       " 'He',\n",
       " 'He',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'he',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_regex = r\"[^a-z](s?he\\b)\"\n",
    "hshe = (re.findall(my_regex, pp, re.IGNORECASE))\n",
    "hshe\n",
    "#len(hshe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a regular expression to find those same \"he\" or \"she\"s, but also match *the word after it*\n",
    "\n",
    "The first four should be:\n",
    "\n",
    "* he is\n",
    "* he had\n",
    "* she told\n",
    "* he came"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he is', 'he had', 'she told', 'he came']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_regex = r\"[^a-z](s?he\\s\\w+)\"\n",
    "hshew = (re.findall(my_regex, pp, re.IGNORECASE))\n",
    "hshew[:4]\n",
    "#len(hshew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use capture groups to save the pronoun (he/she) as one match and the word as another\n",
    "\n",
    "The first five should look like\n",
    "\n",
    "```\n",
    "[('he', 'is'),\n",
    " ('he', 'had'),\n",
    " ('she', 'told'),\n",
    " ('he', 'came'),\n",
    " ('he', 'agreed')]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'is'),\n",
       " ('he', 'had'),\n",
       " ('she', 'told'),\n",
       " ('he', 'came'),\n",
       " ('he', 'agreed')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_regex = r\"[^a-z](s?he)\\s(\\w+)\"\n",
    "hshewg = (re.findall(my_regex, pp, re.IGNORECASE))\n",
    "hshewg[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save those matches into a dataframe\n",
    "\n",
    "You can give the column names with `columns=['pronoun', 'verb']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pronoun': 'he', 'verb': 'is'},\n",
       " {'pronoun': 'he', 'verb': 'had'},\n",
       " {'pronoun': 'she', 'verb': 'told'},\n",
       " {'pronoun': 'he', 'verb': 'came'},\n",
       " {'pronoun': 'he', 'verb': 'agreed'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = []\n",
    "\n",
    "for word in hshewg:\n",
    "    word_dict = {}\n",
    "    word_dict[\"pronoun\"] = word[0]\n",
    "    word_dict[\"verb\"] = word[1]\n",
    "    columns.append(word_dict)\n",
    "\n",
    "columns[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times is each pronoun used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pronoun</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he</td>\n",
       "      <td>had</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>she</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he</td>\n",
       "      <td>agreed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pronoun    verb\n",
       "0      he      is\n",
       "1      he     had\n",
       "2     she    told\n",
       "3      he    came\n",
       "4      he  agreed"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    1323\n",
       "he     1054\n",
       "She     325\n",
       "He      234\n",
       "Name: pronoun, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pronoun.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh, wait, clean that up.\n",
    "\n",
    "Make it only 'he' and 'she' lowercase.\n",
    "\n",
    "It should be about 1600 'she' and 1300 'he'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pronoun\"] = df[\"pronoun\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    1648\n",
       "he     1288\n",
       "Name: pronoun, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pronoun.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 20 most common verbs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "was          372\n",
       "had          371\n",
       "could        172\n",
       "is           139\n",
       "would         94\n",
       "has           70\n",
       "did           67\n",
       "will          50\n",
       "might         46\n",
       "should        41\n",
       "felt          38\n",
       "must          37\n",
       "said          33\n",
       "saw           32\n",
       "added         31\n",
       "thought       31\n",
       "then          26\n",
       "replied       22\n",
       "looked        21\n",
       "continued     21\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.verb.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 20 most common verbs for 'he', and the top 20 most common for 'she'\n",
    "\n",
    "**Tip:** Don't use groupby, just filter. If you want to know how, though, you can also look at \"value counts for different categories\" on [this page](http://jonathansoma.com/lede/foundations-2017/classes/more-pandas/class-notes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "was        212\n",
       "had        205\n",
       "could      132\n",
       "is          65\n",
       "would       59\n",
       "did         38\n",
       "felt        33\n",
       "saw         29\n",
       "will        26\n",
       "might       25\n",
       "added       23\n",
       "has         21\n",
       "said        20\n",
       "thought     18\n",
       "then        15\n",
       "should      15\n",
       "found       13\n",
       "must        13\n",
       "soon        12\n",
       "cried       11\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pronoun == \"she\"].verb.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "had        166\n",
       "was        160\n",
       "is          74\n",
       "has         49\n",
       "could       40\n",
       "would       35\n",
       "did         29\n",
       "should      26\n",
       "must        24\n",
       "will        24\n",
       "might       21\n",
       "replied     14\n",
       "may         13\n",
       "came        13\n",
       "thought     13\n",
       "said        13\n",
       "does        12\n",
       "never       12\n",
       "meant       11\n",
       "then        11\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pronoun == \"he\"].verb.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who cries more, men or women? Give me a percentage answer.\n",
    "\n",
    "**Tip:** It's `cried`, because of, you know, how books are written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    0.916667\n",
       "he     0.083333\n",
       "Name: pronoun, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.verb == \"cried\"].pronoun.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much more common is 'he' than 'she' in J.R.R. Tolkein's Fellowship of the Ring? How does that compare to Pride and Prejudice?\n",
    "\n",
    "The book is in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = open(\"C:/Users/Weihua/Documents/Columbia_Summer/foundations/06-20-18/10-homework/data/Lord of the Rings - 01 - The Fellowship of the Ring - J. R. R. Tolkien - 1955.txt\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE FELLOWSHIP OF THE RING\\n\\n\\n\\n\\nBEING THE FIRST PART OF\\n\\nTHE LORD OF THE RINGS\\n\\nBY\\n\\nJ.R.R. TOLKIEN\\n\\n\\n\\n\\n\\nThree Rings for the Elven-kings under the sky,\\n\\nSeven for the Dwarf-lords in their halls of stone,\\n\\nNine for Mortal Men doomed to die,\\n\\nOne for the Dark Lord on his dark throne\\n\\nIn the Land of Mordor where the Shadows lie.\\n\\nOne Ring to rule them all, One Ring to find them,\\n\\nOne Ring to bring them all and in the darkness bind them\\n\\nIn the Land of Mordor where the Shadows lie.\\n\\n\\n\\n\\n\\nCONTENTS\\n\\n\\nCOV'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'had'),\n",
       " ('He', 'was'),\n",
       " ('he', 'wrote'),\n",
       " ('he', 'recorded'),\n",
       " ('he', 'had')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_regex = r\"[^a-z](s?he)\\s(\\w+)\"\n",
    "pv = (re.findall(my_regex, lr, re.IGNORECASE))\n",
    "pv[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pronoun': 'he', 'verb': 'had'},\n",
       " {'pronoun': 'He', 'verb': 'was'},\n",
       " {'pronoun': 'he', 'verb': 'wrote'},\n",
       " {'pronoun': 'he', 'verb': 'recorded'},\n",
       " {'pronoun': 'he', 'verb': 'had'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_lr = []\n",
    "\n",
    "for word in pv:\n",
    "    word_dict = {}\n",
    "    word_dict[\"pronoun\"] = word[0]\n",
    "    word_dict[\"verb\"] = word[1]\n",
    "    columns_lr.append(word_dict)\n",
    "\n",
    "columns_lr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.DataFrame(columns_lr)\n",
    "#df_lr.head()\n",
    "df_lr[\"pronoun\"] = df_lr[\"pronoun\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    0.916667\n",
       "he     0.083333\n",
       "Name: pronoun, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.verb == \"cried\"].pronoun.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he     0.978261\n",
       "she    0.021739\n",
       "Name: pronoun, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr[df_lr.verb == \"cried\"].pronoun.value_counts(normalize=True)\n",
    "#guys in lord of the right cries a lot, that's for sure lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she    1648\n",
       "he     1288\n",
       "Name: pronoun, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pronoun.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he     2986\n",
       "she     156\n",
       "Name: pronoun, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr.pronoun.value_counts()\n",
    "#but then again, there are WAY more man than woman in lord of the ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
